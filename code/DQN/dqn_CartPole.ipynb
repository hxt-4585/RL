{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# 超参数\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.01\n",
    "# greedy policy\n",
    "EPSILON = 0.9\n",
    "# reward discount\n",
    "GAMMA = 0.9\n",
    "# 目标网络更新频率\n",
    "TARGET_REPLACE_ITER = 100\n",
    "# 记忆库容量\n",
    "MEMORY_CAPACITY = 2000\n",
    "# CartPole-v0环境，render_mode=\"human\"意味着环境会以一种适合人类直接观察的方式进行渲染，比如弹出一个窗口来实时展示环境中的场景\n",
    "env = gym.make('CartPole-v1', render_mode=\"human\").unwrapped\n",
    "# 杆子动作的个数，本环境中是离散动作，即只有向左向右\n",
    "N_ACTIONS = env.action_space.n\n",
    "# Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
    "# [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]中分别代表：小车位置的最小值、小车速度的最小值、杆子角度的最小值、杆子角速度的最小值\n",
    "# [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]代表最大值\n",
    "# env.observation_space.shape[0]代表元组的长度，此处用N_STATES代表状态数4，仅仅恰好相等\n",
    "N_STATES = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Discrete' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Discrete' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Module的子类函数必须在构造函数中执行父类的构造函数\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(N_STATES, 50)\n",
    "        self.fc1.weight.data.normal_(0, 0.1)\n",
    "        self.fc2 = nn.Linear(50, N_ACTIONS)\n",
    "        self.fc2.weight.data.normal_(0, 0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        # 创建DQN的两个网络，评估和目标网络\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "        # \n",
    "        self.learn_step_counter = 0\n",
    "        #\n",
    "        self.memory_counter = 0\n",
    "        # 经验回放记忆库，N_STATES * 2 + 2是指 s, a, r, s'\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))\n",
    "        # 优化器\n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        \n",
    "    def choose_action(self, x):\n",
    "        # (4,)变为(1, 4)\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        if np.random.uniform() < EPSILON :\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0]\n",
    "        else:\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "        return action\n",
    "    \n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        # np.hstack(([1, 2, 3, 4], [0, 1], [5, 6, 7, 8]) = [1, 2, 3, 4, 0, 1, 5, 6, 7, 8]\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        # 记忆库满了\n",
    "        index = self.memory_counter % MEMORY_CAPACITY\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "        \n",
    "    def learn(self):\n",
    "        # 每TARGET_REPLACE_ITER轮更新参数\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "        \n",
    "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n",
    "        b_memory = self.memory[sample_index, :]\n",
    "        \n",
    "        b_s = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "        \n",
    "        q_eval = self.eval_net(b_s).gather(b_a)\n",
    "        # detach将该张量从计算图分离，它不会再参与梯度的计算\n",
    "        q_next = self.target_net(b_s_).detach()\n",
    "        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)\n",
    "        loss = self.loss_func(q_eval, q_next)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcementLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
